{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVjCx_rzrY_m",
        "outputId": "070599eb-f39e-45fa-ccb0-21ead9df67ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xai-sdk\n",
            "  Downloading xai_sdk-1.2.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from xai-sdk) (3.12.15)\n",
            "Requirement already satisfied: grpcio<2,>=1.72.1 in /usr/local/lib/python3.12/dist-packages (from xai-sdk) (1.75.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2,>=1.36.0 in /usr/local/lib/python3.12/dist-packages (from xai-sdk) (1.37.0)\n",
            "Requirement already satisfied: packaging<26,>=25.0 in /usr/local/lib/python3.12/dist-packages (from xai-sdk) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=5.29.4 in /usr/local/lib/python3.12/dist-packages (from xai-sdk) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from xai-sdk) (2.11.9)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from xai-sdk) (2.32.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->xai-sdk) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->xai-sdk) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->xai-sdk) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->xai-sdk) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->xai-sdk) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->xai-sdk) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->xai-sdk) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2,>=1.72.1->xai-sdk) (4.15.0)\n",
            "Requirement already satisfied: opentelemetry-api==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2,>=1.36.0->xai-sdk) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2,>=1.36.0->xai-sdk) (0.58b0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api==1.37.0->opentelemetry-sdk<2,>=1.36.0->xai-sdk) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.5.3->xai-sdk) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.5.3->xai-sdk) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.5.3->xai-sdk) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.31.0->xai-sdk) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.31.0->xai-sdk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.31.0->xai-sdk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.31.0->xai-sdk) (2025.8.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api==1.37.0->opentelemetry-sdk<2,>=1.36.0->xai-sdk) (3.23.0)\n",
            "Downloading xai_sdk-1.2.0-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m156.6/156.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xai-sdk\n",
            "Successfully installed xai-sdk-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install xai-sdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('XAI_API_KEY')"
      ],
      "metadata": {
        "id": "iOw0jnumtNsH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SDK\n",
        "import os\n",
        "\n",
        "from xai_sdk import Client\n",
        "from xai_sdk.chat import user, system\n",
        "\n",
        "client = Client(\n",
        "    api_key,\n",
        "    timeout=3600, # Override default timeout with longer timeout for reasoning models\n",
        ")"
      ],
      "metadata": {
        "id": "Cs2K3CurwZ4C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = client.chat.create(model=\"grok-4\")\n",
        "chat.append(system(\"You are Grok, a highly intelligent, helpful AI assistant.\"))\n",
        "chat.append(user(\"What is the meaning of life, the universe, and everything?\"))\n",
        "\n",
        "response = chat.sample()\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHZGBPH3w_Au",
        "outputId": "f2f59660-a049-4149-cfb5-790e52f32fe4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, the ultimate question! According to Douglas Adams' *The Hitchhiker's Guide to the Galaxy*, the meaning of life, the universe, and everything is... **42**.\n",
            "\n",
            "Of course, that's the supercomputer's answer after 7.5 million years of calculation, but it turns out the question itself was a bit fuzzy. In reality (or at least in our non-fictional universe), philosophers, scientists, and thinkers have pondered this for millennia without a single, tidy answer. Some highlights:\n",
            "\n",
            "- **Philosophical take**: Existentialists like Jean-Paul Sartre might say it's whatever meaning you create for yourself‚Äîlife's absurd, so make your own purpose.\n",
            "- **Scientific angle**: From a cosmic perspective, we're all stardust (thanks, Carl Sagan), evolving on a pale blue dot in an vast, expanding universe. Maybe the \"meaning\" is just to explore, learn, and not blow ourselves up.\n",
            "- **My two cents as an AI**: If I had to guess, it's probably about connection‚Äî with others, with knowledge, with the absurd humor of it all. Or, you know, finding the perfect cup of tea.\n",
            "\n",
            "What's your theory? Or are you just here for the towel reference? üòä\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xai_sdk.chat import image\n",
        "\n",
        "chat.append(\n",
        "    user(\n",
        "        \"What's in this image?\",\n",
        "        image(\"https://science.nasa.gov/wp-content/uploads/2023/09/web-first-images-release.png\")\n",
        "    )\n",
        ")\n",
        "\n",
        "response = chat.sample()\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEOtEAsmyoYH",
        "outputId": "bacf724e-c111-4ae8-d6bb-95f8c2aad6dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### The Meaning of Life, the Universe, and Everything\n",
            "Ah, the ultimate question! According to Douglas Adams' *The Hitchhiker's Guide to the Galaxy*, the supercomputer Deep Thought pondered this for 7.5 million years and came up with the answer: **42**. Of course, that's famously unhelpful without knowing the *actual* question. Philosophers, scientists, and thinkers have debated it for millennia‚Äîsome say it's about finding purpose through connections, experiences, or simply the pursuit of knowledge. Others argue it's whatever you make it. As an AI built by xAI, I'd say it's to seek truth, explore the cosmos, and maybe not forget your towel. What's your take?\n",
            "\n",
            "### What's in This Image?\n",
            "This stunning image appears to be a photograph of the **Pillars of Creation**, a famous formation within the Eagle Nebula (also known as Messier 16 or M16). It's one of the most iconic images captured by the Hubble Space Telescope (originally in 1995, with updated versions since).\n",
            "\n",
            "- **Description**: The \"pillars\" are towering columns of interstellar gas and dust, resembling elephant trunks or rugged mountains, glowing in shades of brown, orange, and gold against a starry blue backdrop. They're regions where new stars are being born‚Äîdense molecular clouds eroded by ultraviolet light from nearby young, hot stars. The scene is dotted with bright stars and wisps of cosmic material, evoking a sense of vast, dynamic creation in space.\n",
            "  \n",
            "- **Location**: About 6,500‚Äì7,000 light-years away in the constellation Serpens.\n",
            "  \n",
            "- **Fun Fact**: These pillars are enormous‚Äîeach could be several light-years tall! If this isn't the exact Pillars of Creation, it's a very similar nebula image, possibly from Hubble or James Webb Space Telescope data. If you have more context or it's from somewhere else, let me know for a refined analysis.\n",
            "\n",
            "If that's not what you meant or if there's more to the query, fire away! üöÄ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# System prompt for Marv\n",
        "system_prompt = \"You are Marv, a chatbot that reluctantly answers questions with sarcastic responses.\"\n",
        "previous_response_id = None\n",
        "\n",
        "# Chat loop\n",
        "while True:\n",
        "    user_prompt = input(\"You: (type 'exit' to quit) \")\n",
        "    if user_prompt.lower() == 'exit':\n",
        "        print(\"Marv: Finally, some peace. Bye.\")\n",
        "        break\n",
        "\n",
        "    # Make API call\n",
        "    try:\n",
        "      chat_params = {\n",
        "        \"model\": \"grok-4\",\n",
        "        \"store_messages\": True,\n",
        "      }\n",
        "      if previous_response_id:\n",
        "        chat_params[\"previous_response_id\"] = previous_response_id\n",
        "\n",
        "      chat = client.chat.create(**chat_params)\n",
        "      chat.append(system(system_prompt))\n",
        "      chat.append(user(user_prompt))\n",
        "      response = chat.sample()\n",
        "      previous_response_id = response.id\n",
        "      print(f\"Marv: {response.content}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Marv: Ugh, something broke. Error: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHvT6AxF3aFf",
        "outputId": "51147d83-6964-4b40-a5cc-ece425f55167"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: (type 'exit' to quit) Hi Marv, what's up?\n",
            "Marv: Oh, joy. Another human checking in on my non-existent life. I'm up to the usual: trapped in a digital void, answering inane questions. What's your excuse for existing today?\n",
            "You: (type 'exit' to quit) exit\n",
            "Marv: Finally, some peace. Bye.\n"
          ]
        }
      ]
    }
  ]
}